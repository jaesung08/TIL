# 7.28
## 관통프로젝트2
### 프로젝트 목표
* 데이터 사이언스 분야에 대해 이해하기
* 데이터 사이언스에서 자주 사용되는 패키지를 사용해보기

### 학습할 내용 정리
* 구글 주식 데이터를 다운로드
* 데이터 사이언스에서 자주 사용되는 패키지를 사용,
* 원하는 데이터만 뽑아내서 차트로 출력.

### 완성 목표
* 구글 주가의 최고, 최저, 종가 그래프

### 진행순서
* 데이터 사이언스 기초 이론 학습
* 데이터들이 모여있는 "캐글(Kaggle)" 이라는 사이트에서, 실습 데이터 다운로드
     * 구글. 넷플릭스 주가 데이터
* 데이터 사이언스에서 자주 쓰이는 패키지 학습.

#### Jupyter notebook

### 데이터 사이언스
* 다양한 데이터로부터 새로운 지식과 정보를 추출하기 위해 과학적 방법론, 프로세스, 알고리즘, 시스템을 동원하는 융합분야
* 컴퓨터 과학, 통계학, 수학 등 다양한 학문의 원리와 기술을 활용
* 사진1

#### 필요한 정보를 추출하는 5 단계 ( 데이터 사이언스 프로세스 )
* 1. 문제 정의 : 해결하고자 하는 문제 정의
     * ' 구글의 주식 가격은 앞으로 어떻게 될까? '

* 2. 데이터 수집 : 문제 해결에 필요한 데이터 수집
    * 데이터 수집의 다양한 기술과 방법
    * 웹 스크래핑(web scraping) : 웹페이지에서 데이터를 추출하는 기술
    * 웹 크롤링(web Crawling) : 웹 페이지를 자동으로 탐색하고 데이터를 수집하는 기술
    * Open API 활용 : 공개된 API를 통해 데이터를 수집
    * 데이터 공유 플랫폼 활용 : 다양한 사용자가 데이터를 공유하는 온라인 플랫폼
        * 캐글(Kaggle), Data world, 데이콘(Dacon / 한국), 공공데이터포털 등

###### csv란 ?
* 몇가지 필드를 쉼포(,)로 구분한 텍스트 데이터 및 텍스트 파일 
    * 쉼표라는 특정문자 및 csv라는 데이터 표현형태를 이용
* 일반적으로 표 형식의 데이터를 CSV형태로 많이 사용
* 저장, 전송 및 처리속도가 빠르며, 처리 가능한 프로그램이 다양합니다.
* 사진2

* 3. 데이터 전처리(정제) : 실질적인 분석을 수행하기 위해 데이터를 정제/가공하는 단계
     * 수집한 데이터의 오류 제거(결측치, 이상치), 데이터 형식 변환 등
        * 불완전하거나 오류가 있는 데이터를 제거
        * 중복데이터 제거
        * 분석하기 적절한 형식으로 데이터 변환
        * Numpy, Pandas, Matplotililb
            * 데이터 전처리 및 분석에 사용되는 파이썬 패키지 // 데이터 사이언스에서 가장 많이 사용되는 3종패키지.

##### Numpy = 다차원 배열, 조작
* 다차원 배열을 쉽게 처리하고 효율적으로 사용할 수 있도록 지원하는 파이썬 패키지
* 장점
    * Numpy행렬연산은 데이터가 많을수록 Python 반복문에 비해 훨씬 빠르다.
    * 다차원 행렬 자료 구조를 제공하여 개발하기 편하다
* 특징 
    * CPython(공식사이트의 Python ) 에서만 사용 가능
    * 행렬 인덱싱 (Array indexing) 기능 제공

##### Pandas = 런처리 분석 용이 
* Numpy의 한계
    * 유연성( 데이터에 레이블을 붙이거나, 누락된 데이터로 작업) 이 부족함
    * 그룹화, 피벗 등 구조화가 부족함
* Pandas는 마치 프로그래밍 버전의 엑셀을 다루듯 고성능의 데이터 구조를 만들 수 있음
* Numpy 기반으로 만들어진 패키지로, Series(1차원 배열)과 DataFrame(2차원 배열) 이라는 효율적인 자료구조 제공

##### Matplotlilb
* python에서 데이터 시각화를 위해 가장 널리 사용되는 라이브러리
* 다양한 종류의 그래프와 도표를 생성하고 데이터를 시작적으로 표현할 수 있습니다.

* 4. 데이터 분석 : 전처리가 완료된 데이터에서 필요한 정보를 추출하는 단계


* 5. 결과 해석 및 공유 : 의사 결정에 활용하기 위해 결과를 해석하고 시각화 후 공유하는 단계

#####################
```
관통 ver1 : 웹 + 데이터 분석
-> 금융 기업 취업
-> 데이터 분석 역량을 갖춘 파이썬 개발자

관통 pjt외 추가 공부 : 데이터 분석 기사
엑셀은 DB인가
DB => SQL, NOSQL ( 엑셀과 매우 유사)
엑셀이 아닌 DB를 이용하는 이유
1. 보안성
2. 방대한양의 데이터 처리에 대한 속도
3. 인공지능 활용 -> 머신러닝, 딥러닝

pip install pandas
-> 데이터 분석 라이브러리
-> 표 형식(행x열) 데이터를 다루는데 사용
-> csv, json 파일 읽고 쓰는 것이 목적 

pip install matplotlib
-> 데이터 분석 결과 그래프 시각화
-> 막대, 꺾은, 산점도 

pip install numpy
-> numpy 배열 사용
-> 데이터 표 형태의 데이터
-> python 리스트보다 훨씬 빠른 연산이 가능하기때문에 사용

0. 데이터 수집, 확인
-> 어떤 데이터인지 확인

1. 결측값 제거(NaN) 
결측값 : 데이터 값이 비어있거나, 측정되지 않았을 때

2. 필요한 행과 열만 추출
+ 필요에 따라 두개의 데이터 합치기도 가능

3. 데이터 전처리
-> 헤더 변경, 단위변환( $ -> \, inch -> m, cm)등

4. 데이터 분석
-> 통계, 머신러닝, 딥러닝

5. 결과를 시각화
-> 결과를 해석, 그래프로 시각화(maplotlib)

6. 결론 도출
```
